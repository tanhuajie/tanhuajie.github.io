---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>

I am Huajie Tan (Ë∞≠Ê°¶Êù∞), a third-year M.S. student at the School of Computer Science, Peking University, advised by [Prof. Shanghang Zhang](https://pku-hmi-lab.github.io/HMI-Web/leader.html). Previously, I received my dual-degree B.Eng. from Tianjin University (College of Intelligence and Computing & College of Microelectronics) and was honored with the **Outstanding Graduate Award**.

My research focuses on **embodied AI and multi-modal foundation models**. I am currently an intern at the [Beijing Academy of Artificial Intelligence (BAAI)](https://www.baai.ac.cn/en/), exploring pathways toward general-purpose robotic intelligence and real-world deployment of embodied systems. I am also open to collaborative opportunities and research partnerships, feel free to email me: *tanhuajie@stu.pku.edu.cn*. We are also hiring research interns.

Meanwhile, I am now seeking **entrepreneurship opportunities**. I have received multiple **top-tier offers** from leading industry labs, e.g., [*Huawei Top Minds (Âçé‰∏∫Â§©Â∞ë)*](https://career.huawei.com/reccampportal/portal5/topminds.html), [*Tencent QingYun (ËÖæËÆØÈùí‰∫ë)*](https://join.qq.com/qingyun.html), [*JD Tech Genius Team (‰∫¨‰∏úTGT)*](https://campus.jd.com/#/talentProject?tabKey=4), [*BAAI Star (Êô∫Ê∫êÊô∫Êòü)*](https://app.mokahr.com/campus-recruitment/baai/42174#/) and [*Xiaomi Top Talent (Â∞èÁ±≥È°∂Â∞ñËÆ°Âàí)*](https://hr.xiaomi.com/toptalent). If you have a better fit or would like to connect, please also feel free to reach out.

# üî• News
- *2026.01*: üî• Released [RoboBrain 2.5](https://github.com/FlagOpen/RoboBrain2.5), our more powerful embodied foundation model (first author, project lead).
- *2026.01*: üéØ Released our new research paper [Action-Sketcher](https://action-sketcher.github.io/) (first author, project lead).
- *2025.12*: üéØ Released our new research paper [Robo-Dopamine](https://robo-dopamine.github.io) (first author, project lead).
- *2025.10*: üî• Released [LLaVA-OneVision-1.5](https://arxiv.org/pdf/2510.26536), a fully open-source MLLM training pipeline from dataset to framework.
- *2025.10*: üî• Released more advanced [RoboOS-NeXT](https://arxiv.org/pdf/2510.26536) (first author, project lead).
- *2025.09*: üéâ [Reason-RFT](https://tanhuajie.github.io/ReasonRFT/) accepted to **NeurIPS 2025**. See you in San Diego, USA!
- *2025.06*: üéâ Released [RoboBrain 2.0](https://arxiv.org/abs/2507.02029) and [RoboOS](https://flagopen.github.io/RoboOS/) in **BAAI Conference 2025** (first author, project lead).
- *2025.04*: üåç [RoboBrain 1.0](http://arxiv.org/abs/2502.21257/) selected for CVPR 2025‚Äôs official [Embodied AI Trends Commentary](https://cvpr.thecvf.com/Conferences/2025/News/AI_Enhanced_Robotics).
- *2025.02*: üéâ [RoboBrain 1.0](http://arxiv.org/abs/2502.21257/) accepted to **CVPR 2025**.

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Technical Report 2026</div><img src='images/robobrain25.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[RoboBrain 2.5: Depth in Sight, Time in Mind.](https://superrobobrain.github.io/)

BAAI RoboBrain Team

<span style="color: red;">Co-First Author, Project Lead</span>, Technical Report 2026

[**Project**](https://superrobobrain.github.io/) <strong>|</strong>  [**Paper (Coming Soon)**](#) <strong>|</strong> [**Code**](https://github.com/FlagOpen/RoboBrain2.5) ![](https://img.shields.io/github/stars/FlagOpen/RoboBrain2.5) <strong>|</strong> [**Checkpoints**](https://huggingface.co/collections/BAAI/robobrain25)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Technical Report 2025</div><img src='images/robobrain2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[RoboBrain 2.0: See Better. Think Harder. Do Smarter.](https://arxiv.org/abs/2507.02029)

BAAI RoboBrain Team

<span style="color: red;">Co-First Author, Core Contributor</span>, Technical Report 2025

 [**Project**](https://superrobobrain.github.io/) <strong>|</strong>  [**Paper**](https://arxiv.org/abs/2507.02029) <strong>|</strong> [**Code**](https://github.com/FlagOpen/RoboBrain2.5) ![](https://img.shields.io/github/stars/FlagOpen/RoboBrain2.5) <strong>|</strong> [**Checkpoints**](https://huggingface.co/collections/BAAI/robobrain20)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Technical Report 2025</div><img src='images/ov.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal Training](https://arxiv.org/abs/2509.23661)

LLaVA-OneVision Community Contributors

<span style="color: red;">Core Contributor</span>, Technical Report 2025

[**Paper**](https://arxiv.org/abs/2509.23661) <strong>|</strong> [**Code**](https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5) ![](https://img.shields.io/github/stars/EvolvingLMMs-Lab/LLaVA-OneVision-1.5) <strong>|</strong> [**Datasets**](https://huggingface.co/collections/lmms-lab/llava-onevision-15) <strong>|</strong> [**Checkpoints**](https://huggingface.co/collections/lmms-lab/llava-onevision-15)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2025</div><img src='images/reason-rft.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning of Vision Language Models](https://arxiv.org/abs/2503.20752)

**Huajie Tan\***, Yuheng Ji\*, Xiaoshuai Hao\*, Xiansheng Chen, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang

<span style="color: red;">Co-First Author, NeurIPS 2025</span>

 [**Project**](https://tanhuajie.github.io/ReasonRFT/) <strong>|</strong>  [**Paper**](https://arxiv.org/abs/2503.20752) <strong>|</strong> [**Code**](https://github.com/tanhuajie/Reason-RFT) ![](https://img.shields.io/github/stars/tanhuajie/Reason-RFT) <strong>|</strong>  [**Datasets**](https://huggingface.co/datasets/tanhuajie2001/Reason-RFT-CoT-Dataset) <strong>|</strong>  [**Checkpoints**](https://github.com/tanhuajie/Reason-RFT?tab=readme-ov-file#--model-zoo)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2025</div><img src='images/robobrain.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[RoboBrain: A Unified Brain Model for Robotic Manipulation from Abstract to Concrete](https://arxiv.org/abs/2502.21257)

Yuheng Ji\*, **Huajie Tan\***, Jiayu Shi\*, Xiaoshuai Hao\*, Yuan Zhang, Hengyuan Zhang, Pengwei Wang, Mengdi Zhao, Yao Mu, Pengju An, Xinda Xue, Qinghang Su, Huaihai Lyu, Xiaolong Zheng, Jiaming Liu, Zhongyuan Wang, Shanghang Zhang

<span style="color: red;">Co-First Author, CVPR 2025</span>

 [**Project**](https://superrobobrain.github.io/) <strong>|</strong>  [**Paper**](https://arxiv.org/abs/2502.21257) <strong>|</strong> [**Code**](https://github.com/FlagOpen/RoboBrain) ![](https://img.shields.io/github/stars/FlagOpen/RoboBrain) <strong>|</strong>  [**Datasets**](https://huggingface.co/datasets/BAAI/ShareRobot) <strong>|</strong>  [**Checkpoints**](https://huggingface.co/collections/BAAI/robobrain)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ArXiv 2025</div><img src='images/roboos.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration](https://arxiv.org/abs/2510.26536)

**Huajie Tan\***, Cheng Chi\*, Xiansheng Chen\*, Yuheng Ji\*, Zhongxia Zhao, Xiaoshuai Hao, Yaoxu Lyu, Mingyu Cao, Junkai Zhao, Huaihai Lyu, Enshen Zhou, Ning Chen, Yankai Fu, Cheng Peng, Wei Guo, Dong Liang, Zhuo Chen, Mengsi Lyu, Chenrui He, Yulong Ao, Yonghua Lin, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang

<span style="color: red;">Co-First Author, Project Lead</span>, ArXiv 2025

 [**Project**](https://flagopen.github.io/RoboOS/) <strong>|</strong>  [**Paper**](https://arxiv.org/abs/2510.26536) <strong>|</strong> [**Code**](https://github.com/FlagOpen/RoboOS) ![](https://img.shields.io/github/stars/FlagOpen/RoboOS) 

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ArXiv 2025</div><img src='images/robodopamine.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Robo-Dopamine: General Process Reward Modeling for High-Precision Robotic Manipulation](https://arxiv.org/abs/2512.23703)

**Huajie Tan\***, Sixiang Chen\*, Yijie Xu\*, Zixiao Wang, Yuheng Ji, Cheng Chi, Yaoxu Lyu, Zhongxia Zhao, Xiansheng Chen, Peterson Co, Shaoxuan Xie, Guocai Yao, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang

<span style="color: red;">Co-First Author, Project Lead</span>, ArXiv 2025

[**Project**](https://robo-dopamine.github.io/) <strong>|</strong>  [**Paper**](https://arxiv.org/abs/2512.23703) <strong>|</strong> [**Code**](https://github.com/FlagOpen/Robo-Dopamine) ![](https://img.shields.io/github/stars/FlagOpen/Robo-Dopamine) <strong>|</strong>  [**Checkpoints**](https://huggingface.co/collections/tanhuajie2001/robo-dopamine)

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ArXiv 2026</div><img src='images/actionsketcher.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2601.01618)

**Huajie Tan\***, Peterson Co\*, Yijie Xu\*, Shanyu Rong, Yuheng Ji, Cheng Chi, Xiansheng Chen, Qiongyu Zhang, Zhongxia Zhao, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang

<span style="color: red;">Co-First Author, Project Lead</span>, ArXiv 2026

[**Project**](https://action-sketcher.github.io/) <strong>|</strong>  [**Paper**](https://arxiv.org/abs/2601.01618) <strong>|</strong> [**Code**](https://github.com/FlagOpen/Action-Sketcher) ![](https://img.shields.io/github/stars/FlagOpen/Action-Sketcher)

</div>
</div>

# üìñ Educations
- *2023.09 - 2026.06*, Master, School of Computer Science, Peking University, Beijing.
- *2019.09 - 2023.06*, Undergraduate, College of Intelligence and Computing & School of Microelectronics, Tianjin University, Tianjin.

# üíª Internships
- *2024.12 - now*, [Beijing Academy of Artificial Intelligence (BAAI)](https://www.baai.ac.cn), Beijing.
- *2024.05 - 2024.11*, [DeepGlint](https://www.deepglint.com/), Beijing.
